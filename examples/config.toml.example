# gcop-rs Configuration File
# Location: ~/.config/gcop/config.toml
#
# ⚠️  Contains sensitive API keys - DO NOT commit to git!
# Recommended permissions: chmod 600 ~/.config/gcop/config.toml

# ============================================
# LLM Configuration
# ============================================
[llm]
# Default provider: "claude" | "openai" | "ollama"
default_provider = "claude"

# Claude Provider
[llm.providers.claude]
# API key (or use environment variable ANTHROPIC_API_KEY)
api_key = "sk-ant-api03-your-key-here"

# Model selection:
# - claude-sonnet-4-5-20250929 (recommended, balanced performance and cost)
# - claude-opus-4-5-20251101 (most powerful, for complex reviews)
model = "claude-sonnet-4-5-20250929"

# OpenAI Provider
[llm.providers.openai]
# API key (or use environment variable OPENAI_API_KEY)
api_key = "sk-your-openai-key-here"
# Recommended models: gpt-4-turbo | gpt-4 | gpt-3.5-turbo
model = "gpt-4-turbo"

# Ollama Provider (local deployment)
[llm.providers.ollama]
# Endpoint (ensure ollama serve is running)
endpoint = "http://localhost:11434/api/generate"
# Recommended models: codellama:13b | llama2:7b | mistral:7b
# Pull model first: ollama pull codellama:13b
model = "codellama:13b"

# ============================================
# Commit Configuration
# ============================================
[commit]
# Enable diff preview and edit functionality
show_diff_preview = true
allow_edit = true

# Custom prompt (optional)
# custom_prompt = """
# You are a professional engineer generating conventional commits.
# Format: type(scope): brief description
# """

# ============================================
# Review Configuration
# ============================================
[review]
# Minimum issue severity to display: "critical" | "warning" | "info"
min_severity = "info"

# ============================================
# UI Configuration
# ============================================
[ui]
# Enable colored output
colored = true
# Enable verbose logging
verbose = false

# ============================================
# Custom Provider Example
# ============================================
# DeepSeek (OpenAI compatible)
# [llm.providers.deepseek]
# api_style = "openai"
# endpoint = "https://api.deepseek.com/v1/chat/completions"
# model = "deepseek-chat"
# api_key = "your-deepseek-api-key-here"
# # Usage: gcop --provider deepseek commit
